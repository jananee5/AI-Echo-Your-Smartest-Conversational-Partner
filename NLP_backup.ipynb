{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE6L8IkpMh4U",
        "outputId": "1198bf71-ed2a-4ede-bb52-5e4f778f9d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHjhhtp3Mtqv",
        "outputId": "b7378290-e1d5-4746-8a4c-874c76a3d7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sklearn\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import psutil\n",
        "from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ],
      "metadata": {
        "id": "QK1EYK2_MxTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/chatgpt_reviews.csv\")\n",
        "df.head()  # Shows first few rows\n",
        "df.info()  # Check data types and missing values\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmNuKGZdM3Mn",
        "outputId": "b3ec949e-1d0c-48d2-8269-fd23f4e81ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               10000 non-null  object \n",
            " 1   title              10000 non-null  object \n",
            " 2   review             10000 non-null  object \n",
            " 3   rating             10000 non-null  int64  \n",
            " 4   username           10000 non-null  object \n",
            " 5   helpful_votes      10000 non-null  int64  \n",
            " 6   review_length      10000 non-null  int64  \n",
            " 7   platform           10000 non-null  object \n",
            " 8   language           10000 non-null  object \n",
            " 9   location           10000 non-null  object \n",
            " 10  version            10000 non-null  float64\n",
            " 11  verified_purchase  10000 non-null  object \n",
            "dtypes: float64(1), int64(3), object(8)\n",
            "memory usage: 937.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 Convert ratings into sentiment labels\n",
        "def map_rating_to_sentiment(rating):\n",
        "    if rating in [1, 2]:\n",
        "        return 0  # Negative\n",
        "    elif rating == 3:\n",
        "        return 1  # Neutral\n",
        "    else:\n",
        "        return 2  # Positive\n",
        "\n",
        "# ✅ Create the new sentiment label column\n",
        "df[\"sentiment_label\"] = df[\"rating\"].apply(map_rating_to_sentiment)\n"
      ],
      "metadata": {
        "id": "KYu7W44gM7Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ✅ Convert text to numerical vectors (Example: TF-IDF)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_vectorized = tfidf.fit_transform(df[\"review\"]).toarray()\n",
        "\n",
        "# ✅ Apply SMOTE on numeric embeddings\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_vectorized, df[\"sentiment_label\"])\n",
        "\n",
        "print(\"✅ Dataset balanced using SMOTE!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhVOQ8e0M9Lo",
        "outputId": "a76c0ead-8f35-4e30-bbc2-084a5add9e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset balanced using SMOTE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before SMOTE:\", df[\"sentiment_label\"].value_counts())\n",
        "print(\"After SMOTE:\", pd.Series(y_resampled).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6bGd-HNM93W",
        "outputId": "fad873e9-b749-45a4-9a27-38065c7402d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before SMOTE: sentiment_label\n",
            "0    4069\n",
            "2    3988\n",
            "1    1943\n",
            "Name: count, dtype: int64\n",
            "After SMOTE: sentiment_label\n",
            "0    4069\n",
            "2    4069\n",
            "1    4069\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_resampled = np.array(y_resampled.tolist())  # ✅ Use resampled labels\n",
        "\n",
        "class_weights_np = compute_class_weight(\"balanced\", classes=np.unique(labels_resampled), y=labels_resampled)\n",
        "\n",
        "# ✅ Convert to tensor for PyTorch and ensure it's on the correct device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "class_weights_tensor = torch.tensor(class_weights_np, dtype=torch.float).to(device)\n",
        "\n",
        "print(f\"Updated Class Weights After SMOTE: {class_weights_np}\")  # 🚀 Verify weights\n",
        "print(f\"Class weights tensor device: {class_weights_tensor.device}\") # 🚀 Verify device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMUu9y6SM_y7",
        "outputId": "c9e28fbe-dff5-4963-b504-8eb207652456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Class Weights After SMOTE: [1. 1. 1.]\n",
            "Class weights tensor device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# ✅ Download required resources\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# ✅ Initialize lemmatizer & stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# ✅ Add domain-specific stopwords for ChatGPT-related reviews\n",
        "custom_stopwords = {\"ai\", \"chatgpt\", \"bot\", \"response\", \"user\"}  # Example additions\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "# ✅ Define text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # 🔹 Lowercase all text\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # 🔹 Remove special characters, but keep numbers\n",
        "    text = re.sub(r\"\\s+\", \" \", text.strip())  # 🔹 Remove extra spaces\n",
        "    text_tokens = text.split()\n",
        "\n",
        "    # 🔹 Lemmatization with POS tagging for better accuracy\n",
        "    lemmatized_text = \" \".join([lemmatizer.lemmatize(word, pos='v') for word in text_tokens if word not in stop_words])\n",
        "\n",
        "    return lemmatized_text\n",
        "\n",
        "# ✅ Apply preprocessing to dataset\n",
        "df[\"review_cleaned\"] = df[\"review\"].apply(preprocess_text)\n",
        "\n",
        "# ✅ Check processed text\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "TiMo1MnNNCDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9bb636-8e3f-44cf-e0cc-8d621cda0f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date                 title  \\\n",
            "0   2/15/2025            Impressive   \n",
            "1  10/16/2024         Waste of Time   \n",
            "2  10/16/2024         Waste of Time   \n",
            "3  12/21/2024          Not Accurate   \n",
            "4   3/23/2025  Fantastic Experience   \n",
            "\n",
            "                                              review  rating       username  \\\n",
            "0  Mother former community upon vote fact. Sure s...       2          ybass   \n",
            "1  General paper understand main. Or age half won...       5        glenn33   \n",
            "2  Here situation his high stage. Agree certainly...       4       debbie27   \n",
            "3  Rule court behind growth reality. Tonight whos...       1  hannahrussell   \n",
            "4  Case opportunity season road write. Effort gre...       3        cnorton   \n",
            "\n",
            "   helpful_votes  review_length platform language   location  version  \\\n",
            "0             68             78   Mobile       es     Canada      3.0   \n",
            "1             71            193      Web       de      India      4.1   \n",
            "2             66            184      Web       hi      India      4.1   \n",
            "3              5            193      Web       fr     Canada      4.0   \n",
            "4             71            131      Web       hi  Australia      4.1   \n",
            "\n",
            "  verified_purchase  sentiment_label  \\\n",
            "0                No                0   \n",
            "1               Yes                2   \n",
            "2               Yes                2   \n",
            "3               Yes                0   \n",
            "4                No                1   \n",
            "\n",
            "                                      review_cleaned  \n",
            "0  mother former community upon vote fact sure st...  \n",
            "1  general paper understand main age half wonder ...  \n",
            "2  situation high stage agree certainly blue thou...  \n",
            "3  rule court behind growth reality tonight whose...  \n",
            "4  case opportunity season road write effort gree...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# ✅ Load Pre-trained Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# ✅ Define Tokenization Function\n",
        "def tokenize_text(text):\n",
        "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "# ✅ Apply Tokenization Correctly\n",
        "df[\"tokenized\"] = df[\"review_cleaned\"].apply(tokenize_text)\n",
        "\n",
        "# ✅ Extract input IDs and attention mask from tokenized output\n",
        "df[\"input_ids\"] = df[\"tokenized\"].apply(lambda x: x[\"input_ids\"])\n",
        "df[\"attention_mask\"] = df[\"tokenized\"].apply(lambda x: x[\"attention_mask\"])\n",
        "\n",
        "# ✅ Check the tokenized output\n",
        "print(df[[\"input_ids\", \"attention_mask\"]].head())\n"
      ],
      "metadata": {
        "id": "o2G2XrS6NEX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f76bc7e-6fad-4ace-b568-248ff1acbdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           input_ids  \\\n",
            "0  [101, 2388, 2280, 2451, 2588, 3789, 2755, 2469...   \n",
            "1  [101, 2236, 3259, 3305, 2364, 2287, 2431, 4687...   \n",
            "2  [101, 3663, 2152, 2754, 5993, 5121, 2630, 4595...   \n",
            "3  [101, 3627, 2457, 2369, 3930, 4507, 3892, 3005...   \n",
            "4  [101, 2553, 4495, 2161, 2346, 4339, 3947, 2665...   \n",
            "\n",
            "                                      attention_mask  \n",
            "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
            "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
            "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
            "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
            "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# ✅ Load Pre-trained Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# ✅ Define Tokenization Function with Dynamic Padding\n",
        "def tokenize_text(text):\n",
        "    return tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "\n",
        "# ✅ Apply Tokenization\n",
        "df[\"tokenized\"] = df[\"review_cleaned\"].apply(tokenize_text)\n",
        "\n",
        "# ✅ Extract input IDs and attention mask from tokenized output\n",
        "df[\"input_ids\"] = df[\"tokenized\"].apply(lambda x: x[\"input_ids\"].squeeze().tolist())  # Convert tensor to list\n",
        "df[\"attention_mask\"] = df[\"tokenized\"].apply(lambda x: x[\"attention_mask\"].squeeze().tolist())  # Convert tensor to list\n",
        "\n",
        "# ✅ Check tokenized text lengths before padding\n",
        "df[\"review_length\"] = df[\"review_cleaned\"].apply(lambda x: len(x.split()))\n",
        "df[\"token_length\"] = df[\"input_ids\"].apply(lambda x: sum(1 for i in x if i != 0))  # Count non-zero tokens\n",
        "\n",
        "# ✅ Display statistics to confirm improvement\n",
        "print(\"Text Length Stats:\")\n",
        "print(df[[\"review_length\", \"token_length\"]].describe())  # Check min/max/mean lengths\n",
        "\n",
        "# ✅ Check sample tokenized output\n",
        "print(df[[\"input_ids\", \"attention_mask\"]].head())\n"
      ],
      "metadata": {
        "id": "ne8_ZVg9NHRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b57adf-45f4-478e-e9a6-deaf2c4fe2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Length Stats:\n",
            "       review_length  token_length\n",
            "count   10000.000000  10000.000000\n",
            "mean       19.743600     21.743600\n",
            "std         4.915819      4.915819\n",
            "min         3.000000      5.000000\n",
            "25%        16.000000     18.000000\n",
            "50%        20.000000     22.000000\n",
            "75%        24.000000     26.000000\n",
            "max        31.000000     33.000000\n",
            "                                           input_ids  \\\n",
            "0  [101, 2388, 2280, 2451, 2588, 3789, 2755, 2469...   \n",
            "1  [101, 2236, 3259, 3305, 2364, 2287, 2431, 4687...   \n",
            "2  [101, 3663, 2152, 2754, 5993, 5121, 2630, 4595...   \n",
            "3  [101, 3627, 2457, 2369, 3930, 4507, 3892, 3005...   \n",
            "4  [101, 2553, 4495, 2161, 2346, 4339, 3947, 2665...   \n",
            "\n",
            "                                      attention_mask  \n",
            "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
            "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
            "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
            "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
            "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ✅ Convert tokenized inputs to uniform padded tensors\n",
        "input_ids_tensor = torch.nn.utils.rnn.pad_sequence(\n",
        "    [torch.tensor(ids, dtype=torch.long) for ids in df[\"input_ids\"]],\n",
        "    batch_first=True, padding_value=0\n",
        ")\n",
        "\n",
        "attention_mask_tensor = torch.nn.utils.rnn.pad_sequence(\n",
        "    [torch.tensor(mask, dtype=torch.long) for mask in df[\"attention_mask\"]],\n",
        "    batch_first=True, padding_value=0\n",
        ")\n",
        "\n",
        "# ✅ Convert labels to a tensor\n",
        "labels_tensor = torch.tensor(df[\"sentiment_label\"].tolist(), dtype=torch.long)\n",
        "\n",
        "print(\"✅ Successfully converted tokenized inputs to uniform tensors!\")\n",
        "print(f\"Input IDs shape: {input_ids_tensor.shape}\")\n",
        "print(f\"Attention Mask shape: {attention_mask_tensor.shape}\")\n",
        "print(f\"Labels shape: {labels_tensor.shape}\")\n"
      ],
      "metadata": {
        "id": "AOsL4R5pNJmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6425c316-44dc-40df-8837-285cfb5b1523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully converted tokenized inputs to uniform tensors!\n",
            "Input IDs shape: torch.Size([10000, 33])\n",
            "Attention Mask shape: torch.Size([10000, 33])\n",
            "Labels shape: torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "\n",
        "# ✅ Move tensors to CPU for DataLoader compatibility\n",
        "input_ids_tensor = input_ids_tensor.cpu()\n",
        "attention_mask_tensor = attention_mask_tensor.cpu()\n",
        "labels_tensor = labels_tensor.cpu()\n",
        "\n",
        "# ✅ Check device availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ✅ Define Dataset Class (Use CPU tensors to avoid pinning issues)\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_masks, labels):\n",
        "        self.input_ids = input_ids  # 🔹 Stay on CPU for DataLoader compatibility\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_masks[idx],\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "# ✅ Instantiate the Dataset with CPU tensors\n",
        "dataset = SentimentDataset(input_ids_tensor, attention_mask_tensor, labels_tensor)\n",
        "\n",
        "# ✅ Define split sizes (80% training, 20% testing)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# ✅ Perform dataset split\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# ✅ Define DataLoaders for efficient training (pin_memory removed)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "# ✅ Verify\n",
        "print(f\"Training Samples: {len(train_dataset)}\")\n",
        "print(f\"Testing Samples: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "01lNMH2_NMrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10880bb-15d4-4ef2-ba10-62eae1ac87fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Samples: 8000\n",
            "Testing Samples: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_classes):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.transformer = AutoModel.from_pretrained(model_name, return_dict=True)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc = nn.Linear(self.transformer.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        output = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # ✅ Apply dropout before final classification\n",
        "        logits = self.fc(self.dropout(output.last_hidden_state[:, 0, :].float()))\n",
        "\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)  # 🔹 Convert logits into probabilities\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)  # ✅ Apply smoothing\n",
        "\n",
        "            loss = loss_fct(logits, labels.long())\n",
        "\n",
        "            # ✅ Return the calculated loss along with logits and probabilities\n",
        "            return {\"loss\": loss, \"logits\": logits, \"probs\": probs}\n",
        "\n",
        "        # ✅ Return logits and probabilities during evaluation/prediction\n",
        "        return {\"logits\": logits, \"probs\": probs}\n",
        "\n",
        "# ✅ Load Model onto GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SentimentClassifier(\"distilbert-base-uncased\", num_classes=3)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "for param in list(model.transformer.parameters())[:4]:\n",
        "    param.requires_grad = False  # 🔹 Allows upper layers to learn new patterns\n"
      ],
      "metadata": {
        "id": "St9ex3XzNP9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    run_name=\"sentiment_classifier_run\",\n",
        "    save_total_limit=2,\n",
        "    save_steps=250,  # 🔹 More frequent saving\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=1e-7,  # 🔹 Adjusted for stability\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    gradient_accumulation_steps=4,\n",
        "    save_strategy=\"steps\",  # 🔹 More frequent model checkpoints\n",
        "    eval_strategy=\"epoch\",\n",
        "    weight_decay=0.2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,  # 🔹 Less frequent logging\n",
        "    fp16=True,  # 🔹 Speeds up training\n",
        "    fp16_full_eval=True,  # 🔹 Optimizes evaluation speed\n",
        "    report_to=\"none\"  # 🔹 Prevents wandb from being used\n",
        ")\n",
        "\n",
        "print(\"✅ Training setup optimized!\")\n"
      ],
      "metadata": {
        "id": "MHfag67MNSZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce449cbe-a9e4-4e45-fed8-6ea803a981a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training setup optimized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "id": "qeh8cS_PNU9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bde0f3-015e-44ea-b7f9-0baff12fcc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "\n",
        "# ✅ Reset `AccelerateState` to fix the distributed training issue\n",
        "write_basic_config()\n"
      ],
      "metadata": {
        "id": "NtMwSHNNNZ3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9eebea4-4ffb-4d21-b7b5-0ccfc86d9503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW  # 🔹 Use PyTorch’s AdamW instead\n",
        "\n",
        "# ✅ Initialize Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.1)\n",
        "\n",
        "# ✅ Define Learning Rate Scheduler\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"cosine\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=10000\n",
        ")\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[\"loss\"]\n",
        "\n",
        "        # ✅ Apply gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    optimizers=(optimizer, lr_scheduler)  # ✅ Pass both optimizer & scheduler\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "beEcMxMnNcQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "6__dUbCWNklD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "4e84fe5f-1b62-4b11-d82f-0ec51186b26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5000/5000 11:58, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.086500</td>\n",
              "      <td>1.056928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.076000</td>\n",
              "      <td>1.050166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.084200</td>\n",
              "      <td>1.061156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.077200</td>\n",
              "      <td>1.063439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.062200</td>\n",
              "      <td>1.045551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.062700</td>\n",
              "      <td>1.048349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.057400</td>\n",
              "      <td>1.054854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.059900</td>\n",
              "      <td>1.061659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.020800</td>\n",
              "      <td>1.111717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.990700</td>\n",
              "      <td>1.114897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5000, training_loss=1.0543415016174316, metrics={'train_runtime': 718.9714, 'train_samples_per_second': 111.27, 'train_steps_per_second': 6.954, 'total_flos': 0.0, 'train_loss': 1.0543415016174316, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_dataset))  # ✅ Should output `<class 'datasets.Dataset'>`\n"
      ],
      "metadata": {
        "id": "RpXtFsM1NoQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3019985-dcdf-4c46-fc75-59f2b4cf465a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataset.Subset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_labels = np.array([test_dataset.dataset[i][\"labels\"] for i in test_dataset.indices])  # ✅ Speed boost\n"
      ],
      "metadata": {
        "id": "MIU6WrEBbngH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ✅ Predictions on test dataset\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Add these lines to inspect the structure of predictions\n",
        "print(f\"Type of predictions: {type(predictions)}\")\n",
        "print(f\"Type of predictions.predictions: {type(predictions.predictions)}\")\n",
        "print(f\"Shape of predictions.predictions: {predictions.predictions.shape if hasattr(predictions.predictions, 'shape') else 'No shape attribute'}\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "pred_labels = np.array(predictions.predictions[0]).argmax(axis=1)  # ✅ Ensures compatibility\n",
        "\n",
        "# ✅ Compute evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, pred_labels, average='weighted')\n",
        "\n",
        "# ✅ Confusion Matrix visualization\n",
        "conf_matrix = confusion_matrix(test_labels, pred_labels)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1-Score: {f1:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(test_labels, pred_labels))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "T0wcbAKBabYt",
        "outputId": "3ecc933e-7533-40f7-85a0-0bd2d4f1a085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2501' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2501/7500 04:38 < 09:16, 8.99 it/s, Epoch 5/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.905200</td>\n",
              "      <td>1.166084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>1.214442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.922700</td>\n",
              "      <td>1.223230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.841000</td>\n",
              "      <td>1.300555</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of predictions: <class 'transformers.trainer_utils.PredictionOutput'>\n",
            "Type of predictions.predictions: <class 'tuple'>\n",
            "Shape of predictions.predictions: No shape attribute\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.4000\n",
            "✅ Precision: 0.3776\n",
            "✅ Recall: 0.4000\n",
            "✅ F1-Score: 0.3854\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.43      0.43       837\n",
            "           1       0.14      0.07      0.10       337\n",
            "           2       0.42      0.50      0.45       826\n",
            "\n",
            "    accuracy                           0.40      2000\n",
            "   macro avg       0.33      0.34      0.33      2000\n",
            "weighted avg       0.38      0.40      0.39      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IUahL9wd0LR",
        "outputId": "1865574c-c946-4cb0-9624-6ccd3e9a5737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NllDUNtRecqy",
        "outputId": "b9a3ab35-845c-4bf4-9f1f-22af924d18e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# ✅ Load Sentiment Analysis Model\n",
        "sentiment_pipeline = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# ✅ Load and Process Your Dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"sentiment_data.csv\")  # Replace with your dataset file\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# ✅ Streamlit App UI\n",
        "st.title(\"Sentiment Analysis Dashboard\")\n",
        "st.header(\":black[Analysis Based on User Reviews]\")\n",
        "\n",
        "# 📌 **Live Sentiment Prediction**\n",
        "st.subheader(\"🔮 Predict Sentiment for Your Review\")\n",
        "user_review = st.text_area(\"Enter a review to analyze:\")\n",
        "\n",
        "if user_review:\n",
        "    prediction = sentiment_pipeline(user_review)[0][\"label\"]\n",
        "\n",
        "    # ✅ Map model output to \"Positive,\" \"Negative,\" or \"Neutral\"\n",
        "    sentiment_mapping = {\n",
        "        \"POSITIVE\": \"Positive 😊\",\n",
        "        \"NEGATIVE\": \"Negative 😠\",\n",
        "        \"NEUTRAL\": \"Neutral 😐\"\n",
        "    }\n",
        "\n",
        "    # ✅ Show prediction with proper sentiment label\n",
        "    sentiment_result = sentiment_mapping.get(prediction, \"Neutral 😐\")\n",
        "    st.write(f\"**Predicted Sentiment:** {sentiment_result}\")\n",
        "\n",
        "    # ✅ Display Sentiment Color Coding\n",
        "    if prediction == \"POSITIVE\":\n",
        "        st.success(\"This review is positive! 😊\")\n",
        "    elif prediction == \"NEGATIVE\":\n",
        "        st.error(\"This review is negative! 😠\")\n",
        "    else:\n",
        "        st.warning(\"This review seems neutral. 😐\")\n",
        "\n",
        "# 📌 **Overall Sentiment Distribution**\n",
        "st.subheader(\"Overall Sentiment of User Reviews\")\n",
        "df[\"sentiment\"] = df[\"review\"].apply(lambda x: sentiment_pipeline(x)[0][\"label\"])\n",
        "sentiment_counts = df[\"sentiment\"].value_counts()\n",
        "st.bar_chart(sentiment_counts)\n",
        "\n",
        "# 📌 **Sentiment vs. Rating**\n",
        "st.subheader(\"How Does Sentiment Vary by Rating?\")\n",
        "rating_sentiment = df.groupby([\"rating\", \"sentiment\"]).size().unstack()\n",
        "st.line_chart(rating_sentiment)\n",
        "\n",
        "# 📌 **Most Associated Keywords Per Sentiment**\n",
        "st.subheader(\"Most Common Keywords for Each Sentiment\")\n",
        "for sentiment_class in [\"POSITIVE\", \"NEGATIVE\"]:\n",
        "    words = \" \".join(df[df[\"sentiment\"] == sentiment_class][\"review\"])\n",
        "    wordcloud = WordCloud(width=500, height=300, background_color=\"white\").generate(words)\n",
        "    st.image(wordcloud.to_array())\n",
        "\n",
        "st.write(\"✅ **Sentiment analysis results displayed successfully!**\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PIY1CIheesB",
        "outputId": "d19aaa3d-9dd4-4178-d36e-b4f00ab929a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uykIjuxnf3Kd",
        "outputId": "32a65df5-ba66-4610-a06e-47bd04c2d096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "added 22 packages in 1s\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "source": [
        "!ngrok authtoken \"2terU4zhNtE7gaJcw6zOfvfv0yM_5aGUqzHPuFd2fJTaWFfbv\""
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8M5VPXiW7m",
        "outputId": "2f924677-68db-42df-d591-ba48c0cc602f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/.config/ngrok/ngrok.yml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihQfbmfuhOOK",
        "outputId": "173ed467-c812-459f-9927-06e497bfc578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "region: us\n",
            "version: '2'\n",
            "authtoken: 2terU4zhNtE7gaJcw6zOfvfv0yM_5aGUqzHPuFd2fJTaWFfbv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2terU4zhNtE7gaJcw6zOfvfv0yM_5aGUqzHPuFd2fJTaWFfbv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFDJz7dokTvr",
        "outputId": "bf9614d1-94b2-437c-a228-8ae74183f2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Open a tunnel for Streamlit (port 8501)\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"✅ Your Streamlit App is accessible at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8XF9-6fkVg4",
        "outputId": "b4456af2-e10b-4c4a-e663-1c4b78ee9b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Your Streamlit App is accessible at: NgrokTunnel: \"https://face-34-125-254-251.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpnHmR8Dknf6",
        "outputId": "40c8ba87-1e34-4b90-9a29-bdf285cd0e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.254.251:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in atexit callback: <function shutdown at 0x7b6bac939440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 2194, in shutdown\n",
            "    h.release()\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 929, in release\n",
            "    def release(self):\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/server.py\", line 469, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 807, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 520, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ✅ Save the model weights\n",
        "torch.save(model.state_dict(), \"sentiment_model.pth\")\n",
        "\n",
        "# ✅ Save the tokenizer separately if using Hugging Face\n",
        "tokenizer.save_pretrained(\"sentiment_tokenizer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIfl3bE8luta",
        "outputId": "c945bbea-1a4b-4e9a-9dc8-202db5314a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sentiment_tokenizer/tokenizer_config.json',\n",
              " 'sentiment_tokenizer/special_tokens_map.json',\n",
              " 'sentiment_tokenizer/vocab.txt',\n",
              " 'sentiment_tokenizer/added_tokens.json',\n",
              " 'sentiment_tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"sentiment_model.pth\")  # ✅ Downloads model weights\n"
      ],
      "metadata": {
        "id": "-XPadbwGl7hd",
        "outputId": "e2c2850e-a524-4e65-e54b-0597319ad600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f6137be3-bf90-4cf5-81b6-1be21c233ae0\", \"sentiment_model.pth\", 265502582)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}